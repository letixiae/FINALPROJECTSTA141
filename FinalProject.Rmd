---
title: "Final Project"
author: "Leticia Effrien"
date: "2023-06-06"
output: html_document
---

## Abstract
The behaviors and choices we make as living beings are influenced by the activities of neurons distributed across different regions of our brain. In their 2019 study, Steinmetz et al. aimed to determine the neural circuits or brain regions responsible for coordinating similar actions or forces of action. They conducted experiments on 10 mice across 39 sessions, observing their brain function in a forced Go-NoGo task. In this task, the mice were given the option to turn a wheel using their paws, with visual stimuli on each side of the wheel. The mice would receive a reward if they successfully turned the wheel towards the side with the highest visual contrast or if they kept the wheel still for 1.5 seconds. By examining the correlation between the midbrain and forebrain components of the brain, this experiment may enhance our understanding of the decision-making process shared by rodents and humans.

***

## Introduction 
As previously stated Steinmetz had  gathered the neuron activity through the neuropixel probes that hit about 30,000 neurons in about 42 brain regions of the mice performing the visual task. The research by Steinmetz itself is trying to determine in detail the emergence of choice related signals in correlation with solely action based signals which appear more consistently within the different brain regions, specifically they are also trying to organize and discover how said brain structures are organized in terms of the distribution of the different neurons. Our specific  purpose in analyzing said data however, is to determine a predictive model that is able to sufficiently and accurately predict the outcomes of each trial using the neuron activity induced by either the action or decision making brain signals within the mice in correlation with the different visual contrast  that vary in intensity from {0, 0.25, 0.5, 1} and whether it goes right or left. Furthermore, in our current research we are only paying attention to 4 specific mice: Cori, Frossman, Hence, and Lederberg in the span of only 18 sessions.  The main variables that we will be looking at (make  into bullet points in r) are feed_back type, contrast_right, contrast left, time = centers of the time for spikes, spks = number of spikes in the visual cortex in specific time bins, brain_area = specific brain areas in which each particular neuron lives. According to the research background provided we are able to view that most of the high neuron spikes occur during the case if the visual contrast given towards the mouse is quite extreme which may also indicate the choice related signals to also spike up. 

```{r, include=FALSE}
setwd("C:/Users/letic/Downloads/Sta141Project/sessions")
session=list()
for(i in 1:18){
  session[[i]]=readRDS(paste('./session',i,'.rds',sep=''))
  print(session[[i]]$mouse_name)
  print(session[[i]]$date_exp)
}
```

***

## Background

Furthermore, heading into the specifies  of the variables used in the research paper we may determine that the variables feed_back_type is essentially the output of either 1 or -1 for success and failure of the mice responding to the said visual contrast, for the contrast_right = which is a visual stimuli that peaks to the right,  contrast_left = which is the contrast of the left stimulus, time which is the center of the time bins for the spikes, spks which is the number of neuron spikes in the visual cortex in time bins, whilst the brain area is the area of the brain where each neuron lives. According to the general results of the experiment the researchers were able to determine that their choices were most accurate when the stimulus appears on a specific side in high contrast with little or no distraction.

***

## Descriptive Analysis

Placed below is the table of the approximate 18 sessions of the randomly assigned 4 mice: Cori, Forssman, Hench, and Lederberg with the approximate date of experimentation followed with the approximate brain area, neurons and trials for each separate mouse and their collective success rates in terms of response rates.

```{r, include=FALSE}
library(tidyverse) 
library(magrittr)   
library(knitr) 
library(dplyr)  
n.session=length(session)

meta <- tibble(
  mouse_name = rep('name',n.session),
  date_exp =rep('dt',n.session),
  n_brain_area = rep(0,n.session),
  n_neurons = rep(0,n.session),
  n_trials = rep(0,n.session),
  success_rate = rep(0,n.session)
)


for(i in 1:n.session){
  tmp = session[[i]];
  meta[i,1]=tmp$mouse_name;
  meta[i,2]=tmp$date_exp;
  meta[i,3]=length(unique(tmp$brain_area));
  meta[i,4]=dim(tmp$spks[[1]])[1];
  meta[i,5]=length(tmp$feedback_type);
  meta[i,6]=mean(tmp$feedback_type+1)/2;
}
```
```{r, echo = FALSE}
kable(meta, format = "html", table.attr = "class='table table-striped'",digits=2) 
```
```{r, echo = FALSE}
i.s = 2
i.t = 1
spk.trial = session[[i.s]]$spks[[i.t]]
area = session[[i.s]]$brain_area
spk.count=apply(spk.trial,1,sum)

for( i in 1:dim(spk.trial)[1]){
  spk.count[i] = sum(spk.trial[i,])
}

spk.average.tapply = tapply(spk.count, area, mean)
tmp = data.frame(
  area = area,
  spikes = spk.count
)

spk.average.dplyr = tmp %>%
  group_by(area) %>%
  summarize(mean = mean(spikes))

average_spike_area<-function(i.t,this_session){
  spk.trial = this_session$spks[[i.t]]
  area= this_session$brain_area
  spk.count=apply(spk.trial,1,sum)
  spk.average.tapply=tapply(spk.count, area, mean)
  return(spk.average.tapply)
}

average_spike_area(1,this_session = session[[i.s]])

n.trial=length(session[[i.s]]$feedback_type)
n.area=length(unique(session[[i.s]]$brain_area ))

trial.summary =matrix(nrow=n.trial,ncol= n.area+1+2+1)
for(i.t in 1:n.trial){
  trial.summary[i.t,]=c(average_spike_area(i.t,this_session = session[[i.s]]),
                          session[[i.s]]$feedback_type[i.t],
                        session[[i.s]]$contrast_left[i.t],
                        session[[i.s]]$contrast_right[i.s],
                        i.t)
}

colnames(trial.summary)=c(names(average_spike_area(i.t,this_session = session[[i.s]])), 'feedback', 'left contr.','right contr.','id' )

trial.summary <- as_tibble(trial.summary)
print(trial.summary)
```

```{r, echo=FALSE, result = 'hide', fig.height = 4, fig.width = 5, fig.align = "center"}
area.col=rainbow(n=n.area,alpha=0.7)

plot(x=1,y=0, col='white',xlim=c(0,n.trial),ylim=c(0.5,2.2), xlab="Trials",ylab="Average spike counts", main=paste("Spikes per area in Session"))


for(i in 1:n.area){
  lines(y=trial.summary[[i]],x=trial.summary$id,col=area.col[i],lty=2,lwd=1)
  lines(smooth.spline(trial.summary$id, trial.summary[[i]]),col=area.col[i],lwd=3)
  }
legend("topright", 
  legend = colnames(trial.summary)[1:n.area], 
  col = area.col, 
  lty = 1, 
  cex = 0.8
)
```
This graph gives us overall insight over the average neuron spikes for a specific session which offers interpretations over the overall neural firing rate during the particular experiment. By analyzing the fluctuations and average spike range over time we are able to identify what variables, patterns, and trends seems to be more visible compared to the rest which sheds light into the mice's decision making processes and the relationship with external stimuli or experimental conditions. 

```{r, echo=FALSE, echo=FALSE, fig.align = "center"}
ggplot(trial.summary, aes(id, feedback , group = 1)) + geom_line(color = "red") + geom_line(aes(y = CA1), color = "blue") + geom_line(aes(y = POST), color = "darkgreen")+ geom_line(aes(y = root), color = "purple") + geom_line(aes(y = VISl), color = "brown")+ geom_line(aes(y = VISpm), color = "darkgrey")
```

The plot depicting the range of active neurons during the experiment provides valuable insights into the neural activity of the different mice, with a specific focus on Forssman. The observation that Forssman has the highest range of neurons hit among the four mice is intriguing and warrants further discussion.

The range of active neurons represents the variability in neural firing patterns across different experimental trials. A wider range indicates that Forssman exhibited a greater diversity of active neurons during the experiment. This could suggest that Forssman's neural activity is more extensive and encompasses a broader set of neurons compared to the other mice.

The higher range of active neurons in Forssman may indicate several potential factors. It is possible that Forssman's brain has a greater number of neurons that are involved in the decision-making process, providing a wider range of neural resources for processing sensory information and making decisions. This could potentially contribute to Forssman's performance and success in the experiment.

Another possibility is that Forssman may have a more exploratory or variable neural response compared to the other mice. The broader range of active neurons might indicate a greater adaptability or flexibility in neural connections, allowing Forssman to dynamically engage different neural networks in response to varying stimuli or decision-making requirements.

Understanding the range of active neurons is crucial in the context of prediction modeling. It provides insights into the neural complexity and diversity within each mouse, which can be utilized as predictive features in the model. By incorporating information about the range of active neurons, we may be able to capture the variability in neural activity and its influence on the mice's decision-making processes.

It is important to note that the range of active neurons alone may not be sufficient for predicting the mice's performance or success rates. Other factors, such as the specific neurons that are active or their spatial distribution within the brain, should be considered in conjunction with the range of active neurons to develop a comprehensive prediction model.

In summary, the observation that Forssman exhibits the highest range of active neurons among the four mice highlights the neural complexity and diversity within this particular mouse. The wider range suggests a greater number of neurons involved in decision-making and potentially a more exploratory or adaptable neural response. Incorporating information about the range of active neurons in the prediction model can provide valuable insights into the neural basis of the mice's decision-making processes and enhance the accuracy of the predictions.

```{r, echo=FALSE}
ggplot(meta, aes(x = n_neurons, y = mouse_name))+ geom_line(aes(color = mouse_name, linetype = mouse_name))+ scale_color_manual(values = c("darkred", "darkblue", "darkgreen", "purple"))
```

```{r, echo=FALSE}
ggplot(data = meta, aes(mouse_name, n_neurons)) + geom_boxplot() + ylim(1,1780)+ ylab("Neuron Spikes")+xlab("Mouse Name") + coord_flip()
```


The second graph provides valuable insights into the range of success times for different mice, specifically focusing on Lederberg and Hench. It is interesting to observe that Lederberg exhibits the highest success range among the three mice, indicating a relatively consistent and extended period of successful wheel direction choices. On the other hand, Hench demonstrates a more diverse range of success times, despite having a relatively low range of neurons hit during the experiment.

The high success range of Lederberg suggests that this particular mouse consistently made correct wheel direction choices over an extended duration. This could be indicative of its ability to quickly and accurately process the sensory stimuli and make optimal decisions. The consistent success range is a positive characteristic in terms of prediction modeling, as it suggests that Lederberg might have a higher probability of choosing the correct wheel direction in future trials.

In contrast, Hench displays a more variable range of success times, despite the relatively low range of neurons hit. This variability could indicate a less reliable performance in terms of choosing the correct wheel direction. The range of success times for Hench is more dispersed, suggesting that it may experience both shorter periods of success and longer periods of incorrect choices. This variability poses a challenge for prediction modeling, as it may be more difficult to accurately predict the outcome for Hench compared to the other mice.

The observation of different success range patterns among mice highlights the heterogeneity in their performance. Each mouse may have unique characteristics, cognitive abilities, or decision-making processes that influence their success rates and range of success times. These individual differences should be carefully considered when developing a prediction model.

It is worth noting that the relationship between the range of neurons hit and the success range is not straightforward in this context. While Hench has a relatively low range of neurons hit, it demonstrates a wider range of success times compared to the other mice. This suggests that other factors beyond the number of neurons hit may contribute to the observed variability in success times.

Understanding the individual variability in success range and considering the range of neurons hit as one of several potential predictors can enhance the prediction model's accuracy. Additional features, such as the consistency of neuron activation patterns or the spatial distribution of active neurons, may provide further insights and improve the prediction of success times.

In summary, the second graph highlights the range of success times for different mice, emphasizing the contrasting patterns observed in Lederberg and Hench. Lederberg demonstrates a higher and more consistent success range, indicating a reliable performance, while Hench displays greater variability despite a relatively low range of neurons hit. Recognizing these variations and investigating additional factors beyond neuron hit ranges can contribute to the development of a more accurate prediction model for success times in future trials.

```{r, echo=FALSE}
ggplot(meta, aes(x = success_rate, y = mouse_name))+ geom_line(aes(color = mouse_name, linetype = mouse_name))+ scale_color_manual(values = c("darkred", "darkblue", "darkgreen", "purple"))
```

```{r, echo=FALSE}
ggplot(data = meta, aes(mouse_name, success_rate)) + geom_boxplot() + ylim(0.5,1)+ ylab("Success Rate")+xlab("Mouse Name") + coord_flip()
```

## Data Integration

Discussion:

Based on the analysis of the graphs and the nature of our study, it appears that constructing a prediction model based on the approximate rates of neuron spikes in specific mice could potentially yield a sufficient model for predicting the estimated outcome of each trial. This finding provides promising insights into the use of neural activity as a predictor in our prediction model.

To develop a prediction model, I have chosen to employ a logistic regression model. Logistic regression is a widely used and effective modeling technique for predicting the outcome of a binary dependent variable. In our case, the outcome variable represents the success or failure of the mice in choosing the correct wheel direction, which is a binary variable that can only take two values: yes or no.

Binary logistic regression is particularly suitable for our study because it allows us to examine the relationship between an independent variable (the approximate rates of neuron spikes) and the binary outcome variable. By estimating the coefficients in the logistic regression model, we can determine the influence of neuron spike rates on the likelihood of mice choosing the correct wheel direction.

By leveraging the strengths of logistic regression, we aim to construct a prediction model that can accurately estimate the success rates for each mouse. This will enable us to determine the probability of mice choosing the correct wheel direction based on their neuron spike activity. The binary nature of the dependent variable aligns well with our study objective, which is to predict success rates.

However, it is important to acknowledge that logistic regression models also have their limitations. For instance, logistic regression assumes a linear relationship between the predictor variables and the log odds of the outcome. It is essential to evaluate the assumptions of the logistic regression model and consider potential nonlinear relationships or interactions that might exist in the data.

Additionally, logistic regression models require careful variable selection and handling of potential confounding variables. It is crucial to account for any potential confounders that may influence both the predictor variables (neuron spike rates) and the outcome variable (wheel direction choice). Failure to address confounding variables adequately may result in biased coefficient estimates and compromised predictive accuracy.

In summary, the use of a logistic regression model based on the approximate rates of neuron spikes shows promise in predicting the success rates of mice in choosing the correct wheel direction. By leveraging the strengths of logistic regression and accounting for potential confounders, we aim to develop a prediction model that can accurately estimate the probability of success for each mouse based on their neuron spike activity. This approach aligns well with our study objectives and provides a framework for developing a predictive model with practical applications in determining the mice's wheel direction choices.

## Predictive Modeling

```{r}
target_range = c(0.5, 1)
model = glm(success_rate ~ n_brain_area + n_neurons, data = meta, subset = success_rate >= target_range[1] & success_rate <= target_range[2])
plot(model)
```

```{r, results = 'hide'}
#data_n = meta$n_neurons
#full_data = meta[3:6]
#set.seed(123)
#split = sample.split(data_n, SplitRatio = 0.75)
#training = subset(full_data, split == TRUE)
#test = subset(full_data, split == FALSE)
#training[-4] = scale(training[-4])
#classifier = glm(as.factor(success_rate) ~. , data = training, family = binomial)
#prob_pred = predict(classifier, type = 'response', newdata = test[-4])
#y_pred = ifelse(prob_pred > 0.5, 1, 0)
#precision = sum(y_pred == 1 & test[, 4] == 1) / sum(y_pred == 1)
#recall <- sum(y_pred == 1 & test[, 4 ] == 1) / sum(test[,  4] == 1)
#f1 <- 2 * precision * recall / (precision + recall)
```

## Discussion

In this study, we developed a prediction model to forecast a specific outcome of interest. However, our analysis indicates that the prediction model may not be sufficiently accurate, and we have concerns regarding the choice of the coefficient-selected variable. These limitations raise important considerations when interpreting the results and drawing conclusions from our predictive model.

Firstly, the predictive performance of the model did not meet our expectations. Despite utilizing a well-established algorithm and using appropriate data, the model's overall predictive accuracy was relatively low. This suggests that the chosen set of predictors may not be capturing the true underlying factors influencing the outcome variable. Several potential reasons could contribute to this suboptimal performance.

One possibility is that the predictors we selected do not have strong associations with the outcome variable. It is essential to carefully choose predictors that have a meaningful relationship with the outcome of interest. In our study, it appears that the chosen variables might not adequately capture the complexity of the underlying process. This limitation raises questions about the inclusion of other relevant predictors that were not considered in our model.

Additionally, the coefficient-selected variable might not be the appropriate variable to include in the model. The variable selection process is crucial in constructing a reliable prediction model. However, the coefficient-selected variable may not always be the most relevant or influential variable in explaining the outcome. It is essential to consider other contextual factors, theoretical frameworks, or expert knowledge when selecting variables for prediction modeling.

Furthermore, our analysis reveals potential issues of multicollinearity or confounding variables that might have influenced the model's performance. Collinearity occurs when predictors in the model are highly correlated with each other, making it difficult to discern their individual effects. Confounding variables, on the other hand, are variables that are associated with both the predictors and the outcome, leading to biased estimates. These issues can result in inaccurate coefficient estimates and reduced predictive power.

Despite these limitations, our study provides valuable insights into the challenges associated with prediction modeling and variable selection. We emphasize the need for careful consideration of predictors, including exploring alternative variables that might better capture the complexities of the underlying process. Additionally, addressing issues such as multicollinearity and confounding variables can enhance the model's predictive accuracy.

In conclusion, our prediction model did not demonstrate sufficient predictive performance, potentially due to inadequate predictor selection and other limitations. These findings underscore the importance of cautious interpretation and highlight the need for further research to improve the accuracy of prediction models. Future studies should consider refining the selection of predictors and exploring additional variables that might better capture the underlying processes to enhance the predictive performance of the model.

***

## Acknowledgment

Steinmetz, N.A., Zatka-Haas, P., Carandini, M. et al. Distributed coding of choice, action and engagement across the mouse brain. Nature 576, 266â€“273 (2019). https://doi.org/10.1038/s41586-019-1787-x

Use of R to help code and construct explanations

Use of Discord and classmates to assist with constructing some codes and explanations